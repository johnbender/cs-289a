\documentclass[usletter]{article}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{test}
\usepackage[margin=1.5in]{geometry}

\begin{document}

\makeheader{John Bender}{November 10, 2014}{1}{Midterm Examination}

Only two sources outside the class notes were consulted, \cite{textbook} and \cite{orthsub}.

\begin{enumerate}
  \item How much communication do Alice and Bob need to find out deterministically if their graphs are isomorphic?

    \begin{claim}
      $O(n)$ bits are required.
    \end{claim}

    \begin{proof}
      We assume that graphs can be encoded in $(|E| + |V|) \cdot log(|E| + |V|) \cdot c$ bits for the edges $E$, vertices $V$ and $|G| = |E| + |V|$. Then for input size $n$ we have the following:

      \begin{align*}
        n &= |E| \cdot log(|G|) + |V| \cdot log(|G|) \\
       |V| &= \frac{n}{log(|G|)} - |E|
      \end{align*}

      We also know the following:

      \begin{enumerate}
        \item In the characteristic matrix $M_{\mathsf{ISO_n}}$ each row will have at most $\left (\frac{n}{log(|G|) \cdot c} - |E|\right)!$ entries for all the re-orderings of the vertices in the graph (after adding the constant back in).
        \item For every row $G_i$ where the entry at $i,j$ is one, there is an identical row for $G_j$ because $G_j$ will be isomorphic to the same graphs as $G_i$.
      \end{enumerate}

      By (a) and (b) we know that that rank of $M_{\mathsf{ISO_n}}$ will be:

      \begin{equation}
        2^n - \left (\frac{n}{log(|G|) \cdot c} - |E|\right)!
      \end{equation}

      Which is essentially $2^n$ for sufficiently large $n$. Also, if the number of ones in a given row is essentially $o(1)$ then we would need $O(2^n)$ other rows to find another entry at any given position in the matrix. So for sufficiently large $n$ we have:

      \begin{equation}
        rk_{\mathbb{F}_2} M_{\mathsf{ISO_n}} = O(2^n)
      \end{equation}

      And by the rank bound we have that $D(\mathsf{ISO_n}) = O(n)$ which is tight.
    \end{proof}

  \item Construct a $\mathsf{P}^{\mathsf{cc}}$ communication problem.
    \begin{proof}
      We know the following:

      \begin{enumerate}
        \item For a problem $\{f_n\} \in \mathsf{P}^{\mathsf{cc}}$, a fixed $f_n$ has a protocol tree of height at most $\log^c n$ by the definition of $\mathsf{P}^{\mathsf{cc}}$.
        \item The number of nodes in the protocol tree is at most $2^{\log^c n} - 1$ by (a).
        \item The number of edges in the protocol tree is at most $2^{\log^c n} - 2$ by (a).
      \end{enumerate}

      With the above we can define $A_n(x), B_n(y)$ to be an encoding of the protocol tree at $x$ and $y$ respectively. This restriction on the tree makes the number of nodes linear in the size of the height, $2h$, since at each of the nodes for Alice and Bob for $A_n$ and $B_n$ respectively only one side of the branch is needed.

      Then the encoding of a single node or edge requires at most $\log(4 \log^c n) = \lceil \log (\log^c n) + 2 \rceil$ bits. As a result we have at most $(4 \log^c n) \cdot \lceil \log (\log^c n) + 2 \rceil$ bits for an encoding of the tree. Then the protocol for our complete problem is just a coordinated traversal of the tree where left is $0$ and right is $1$ requiring at most $\log^cn$ single bit communications.

      We know that this protocol is in $\mathsf{P}^{\mathsf{cc}}$ since it requires $\log^c n$ bits of communication and we also know that the range of the reductions is $\{0,1\}^{{(4 \cdot \log^c n) \cdot \lceil \log (\log^c n) + 2 \rceil}$ by the encoding.
    \end{proof}

  \item Let $f : \{0,1\}^n \times \{0,1\}^n \rightarrow \{0,1\}$ be given by $f(x,y) = 1 \Leftrightarrow \Sigma x_i y_i \equiv 0\ (\mathsf{mod}\ 18181)$. Prove that $f$ has no fooling set larger than $n^c$, for some constant $c$.

    \begin{proof}
      We know the following:

      \begin{enumerate}
        \item $rk_{\mathbb{F}_2}\ M_{\mathsf{coIP}_n} = n$
        \item $\forall \mathbb{F}, \mathbb{K}, rk_{\mathbb{F}}\ M = rk_{\mathbb{K}}\ M$ where $\mathbb{F}, \mathbb{K}$ are finite fields.
        \item $\forall \mathbb{F}, f.|fs(f)| \leq (1 + rk_{\mathbb{F}}\ M_f)^2$ where $M_f$ is the characteristic matrix for $f$.
      \end{enumerate}

      From the definition and (a) $f$ has can be seen as $\mathsf{coIP}_n$ in $\mathbb{F}_{18181}$. Then by (b) and (c) we know that $M_f$ has rank $n$ and taken with (d) this implies that the size of the fooling set is certainly no greater than $n^3$.
    \end{proof}

  \item What is the nondeterministic communication complexity of $f$ in the previous problem?

    We know the following:

    \begin{enumerate}
      \item $RS_{\mu}(\mathsf{coIP}_n)$ is $\frac{1}{2^{n-1}}$ in $\mathbb{F}_2$ for the uniform distribution, due to the orthogonality of the subspaces encompassing a given zero-rectangle.
    \end{enumerate}

    In $\mathbb{F}_{18181}$ we expect the same property to hold so the distribution over any given rectangle is bounded by $\frac{1}{2^{n-1}}$ which gives us a lower bound on the nondeterministic communication complexity of $\lceil \log 2^{n-1} \rceil $ which is tight.

  \item On input linear subspaces $A, B \subseteq \mathbb{F}_2^n$ prove that $\Theta(n^2)$ bits of nondeterministic communication are necessary and sufficient to check if $A$ and $B$ are orthogonal.

    \begin{proof}
      We know the following:

      \begin{enumerate}
        \item Both $A$ and $B$ can be represented as their basis which contains $m$ (which is order $n$) linearly independent vectors of order $n$ bits ($O(n^2)$).
        \item $A$ and $B$ are orthogonal if $\forall x \in A, y \in B. \langle x, y \rangle = 0$, from \cite{orthsub}
        \item $N(\mathsf{IP_n}) = O(n)$
      \end{enumerate}

      By (a), (b) and (c) we know that $O(n^2)$ bits is sufficient to check the orthogonality of the subspaces because we can run the inner product protocol $n$ times, once for each vector in the basis for $A$ or $B$.

      Further, we can't do any better than the $n$ nondeterministic bits required for each inner product so if we were to reduce the required communication it would have to be by sending fewer vectors from our basis. Assume, that we can verify the orthogonality of $A$ and $B$ by sending fewer than $m$ vectors, this implies that there is some number of $m'$ that forms a basis for $A$ or $B$, but this contradicts our assumption that we were making use of the basis initially. So $O(n^2)$ is also necessary.
    \end{proof}

  \item Alice and Bob have a matrix over some finite field. How much communication do they need to determine with accuracy 99\% if their matrices are inverses of each other?

    \begin{proof}
      We know the following, assuming Alice's matrix is $A$ and Bob's is $B$:

      \begin{enumerate}
        \item There is exactly one matrix such that $AB = I$
        \item $R_{\epsilon}(EQ_n) = \lceil \log \frac{1}{\epsilon} \rceil + 1$
        \item This problem is equivalent to finding the inverse of $A$ and then comparing for equality with $B$ (or vice-versa).
      \end{enumerate}

      By (a), (b) and (c) we know that this problem has worst case complexity $\lceil \log \frac{1}{\epsilon} \rceil + 1$, which is a constant for a fixed $\epsilon$.
    \end{proof}
\end{enumerate}

\newpage

\bibliography{1}
\bibliographystyle{plain}

\end{document}
